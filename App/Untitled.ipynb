{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95634c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import vectorize\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import streamlit as st\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import tweepy, pandas, configparser, re, nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "486ea783",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "\n",
    "def count_vectorizer(x_train, x_test):\n",
    "    x_train  = vectorizer.fit_transform(x_train)\n",
    "    x_test = vectorizer.transform(x_test)\n",
    "    return x_train, x_test\n",
    "\n",
    "def tfid_vectorizer(X_train_tfidf, X_test_tfidf):\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train_tfidf)\n",
    "    X_test_tfidf = tfidf.transform(X_test_tfidf)\n",
    "    return X_train_tfidf, X_test_tfidf\n",
    "\n",
    "\n",
    "\n",
    "def tweet_search(city, type, approach, split_size):\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('.\\\\pages\\\\config.ini')\n",
    "\n",
    "    consumer_key = config['twitter']['api_key']\n",
    "    consumer_secret = config['twitter']['api_key_secret']\n",
    "    access_token = config['twitter']['access_token']\n",
    "    access_secret = config['twitter']['access_token_secret']\n",
    "\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    query1 = city + \" \" + 'traffic -filter:retweets'\n",
    "    query2 = city + \" \" + 'roadblock -filter:retweets'\n",
    "    query3 = city + \" \" + 'accident -filter:retweets'\n",
    "    query4 = city + \" \" + 'road closed -filter:retweets'\n",
    "    query5 = city + \" \" + 'blocked -filter:retweets'\n",
    "    query6 = city + \" \" + 'traffic jam -filter:retweets'\n",
    "\n",
    "    \n",
    "    tweets_array = []\n",
    "    tweets1 = tweepy.Cursor(api.search_tweets, q=query1, lang='en', tweet_mode='extended', result_type='recent').items(500)\n",
    "    tweets2 = tweepy.Cursor(api.search_tweets, q=query2, lang='en', tweet_mode='extended', result_type='recent').items(500)\n",
    "    tweets3 = tweepy.Cursor(api.search_tweets, q=query3, lang='en', tweet_mode='extended', result_type='recent').items(500)\n",
    "    tweets4 = tweepy.Cursor(api.search_tweets, q=query4, lang='en', tweet_mode='extended', result_type='recent').items(500)\n",
    "    tweets5 = tweepy.Cursor(api.search_tweets, q=query5, lang='en', tweet_mode='extended', result_type='recent').items(500)\n",
    "    tweets6 = tweepy.Cursor(api.search_tweets, q=query6, lang='en', tweet_mode='extended', result_type='recent').items(500)\n",
    "    for tweet in tweets1:\n",
    "        tweets_array.append([tweet.user.screen_name, tweet.full_text,tweet.created_at])\n",
    "    for tweet in tweets2:\n",
    "        tweets_array.append([tweet.user.screen_name, tweet.full_text,tweet.created_at])\n",
    "    for tweet in tweets3:\n",
    "        tweets_array.append([tweet.user.screen_name, tweet.full_text,tweet.created_at])\n",
    "    for tweet in tweets4:\n",
    "        tweets_array.append([tweet.user.screen_name, tweet.full_text,tweet.created_at])\n",
    "    for tweet in tweets5:\n",
    "        tweets_array.append([tweet.user.screen_name, tweet.full_text,tweet.created_at])\n",
    "    for tweet in tweets6:\n",
    "        tweets_array.append([tweet.user.screen_name, tweet.full_text,tweet.created_at])\n",
    "\n",
    "    df = pandas.DataFrame(tweets_array, columns=['username', 'tweet', 'timestamp'])\n",
    "    df['date'] = pandas.to_datetime(df['timestamp']).dt.date\n",
    "    df['time'] = pandas.to_datetime(df['timestamp']).dt.time\n",
    "    df = df.drop('timestamp', axis=1)   \n",
    "\n",
    "    #streamlit.dataframe(df, height=1000, width=1000)\n",
    "\n",
    "    samp_df = pandas.read_csv(\".\\\\pages\\\\trainingData.csv\")\n",
    "    samp_df['Classification'] = samp_df['class'].apply(pp.convert)\n",
    "    samp_df['processed_text'] = samp_df['text'].apply(pp.lemmatization)\n",
    "    samp_df['processed_text'].apply(pp.preprocess_tweets)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(samp_df.processed_text, samp_df.Classification, test_size=split_size, random_state=101)\n",
    "    \n",
    "    if type == 1:\n",
    "        x_train, x_test = count_vectorizer(x_train, x_test)\n",
    "    elif type == 2:\n",
    "        x_train, x_test = tfid_vectorizer(x_train, x_test)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(x_train, y_train)\n",
    "    rf_train_score = rf.score(x_train,y_train)\n",
    "    rf_test_score = rf.score(x_test,y_test)\n",
    "\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(x_train, y_train)\n",
    "    nb_train_score = nb.score(x_train,y_train)\n",
    "    nb_test_score = nb.score(x_test,y_test)\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(x_train, y_train)\n",
    "    logreg_train_score = logreg.score(x_train,y_train)\n",
    "    logreg_test_score = logreg.score(x_test,y_test)\n",
    "\n",
    "    predictions1 = logreg.predict(x_test)\n",
    "    logreg_acc_score = accuracy_score(y_test, predictions1)\n",
    "    predictions2 = nb.predict(x_test)\n",
    "    nb_acc_score = accuracy_score(y_test, predictions2)\n",
    "    predictions3 = rf.predict(x_test)\n",
    "    rf_acc_score =  accuracy_score(y_test, predictions3)\n",
    "\n",
    "    d = {\n",
    "    'Logistic Regression' : [logreg_test_score, logreg_train_score, logreg_acc_score],\n",
    "    'Naive-Bayes' : [nb_test_score ,nb_train_score, nb_acc_score],\n",
    "    'Random Forest' : [rf_test_score, rf_train_score, rf_acc_score]\n",
    "    }\n",
    "    labels = [\"Test Score\", \"Train Score\", \"Accuracy Score\"]\n",
    "    scores_df = pd.DataFrame(d, index=labels)\n",
    "\n",
    "\n",
    "    # PREDICTION:\n",
    "\n",
    "    raw_tweets = df['tweet']\n",
    "    raw_tweets = raw_tweets.apply(pp.preprocess_tweets)\n",
    "    raw_tweets = raw_tweets.apply(pp.lemmatization)\n",
    "    \n",
    "    if type == 1:\n",
    "        bow = vectorizer.transform(raw_tweets)\n",
    "        if approach == 1:\n",
    "            predictions = logreg.predict(bow)\n",
    "        elif approach == 2:\n",
    "            predictions = nb.predict(bow)\n",
    "        else:\n",
    "            predictions = rf.predict(bow)\n",
    "    \n",
    "    elif type == 2:\n",
    "        bow = tfidf.transform(raw_tweets)\n",
    "        if approach == 1:\n",
    "            predictions = logreg.predict(bow)\n",
    "        elif approach == 2:\n",
    "            predictions = nb.predict(bow)\n",
    "        else:\n",
    "            predictions = rf.predict(bow)\n",
    "    \n",
    "\n",
    "    df['predicted_class'] = predictions\n",
    "    new_df = df[df['predicted_class'] == 1]\n",
    "    new_df = new_df.drop('predicted_class', axis=1)\n",
    "    new_df = new_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "    # ROC\n",
    "\n",
    "    r_probs = [0 for _ in range(len(y_test))]\n",
    "    rf_probs = rf.predict_proba(x_test)\n",
    "    nb_probs = nb.predict_proba(x_test)\n",
    "    logreg_probs = logreg.predict_proba(x_test)\n",
    "    \n",
    "    rf_probs = rf_probs[:, 1]\n",
    "    nb_probs = nb_probs[:, 1]\n",
    "    logreg_probs = logreg_probs[:, 1]\n",
    "\n",
    "    r_auc = roc_auc_score(y_test, r_probs)\n",
    "    rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "    nb_auc = roc_auc_score(y_test, nb_probs)\n",
    "    logreg_auc = roc_auc_score(y_test, logreg_probs)\n",
    "\n",
    "    r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "    rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "    nb_fpr, nb_tpr, _ = roc_curve(y_test, nb_probs)\n",
    "    logreg_fpr, logreg_tpr, _ = roc_curve(y_test, logreg_probs)\n",
    "\n",
    "    return df, new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60632d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, new_df = tweet_search(\"seattle\",1,1,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "109ffff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "955"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81f181a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TotalTrafficSEA</td>\n",
       "      <td>Delays up to two hours in #Edmonds/Kingston on...</td>\n",
       "      <td>2022-07-16</td>\n",
       "      <td>16:30:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TotalTrafficSEA</td>\n",
       "      <td>Blocked due to accident in #HbrIsland/WestSeat...</td>\n",
       "      <td>2022-07-16</td>\n",
       "      <td>02:15:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TotalTrafficSEA</td>\n",
       "      <td>Blocked due to accident in #HbrIsland/WestSeat...</td>\n",
       "      <td>2022-07-16</td>\n",
       "      <td>02:15:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TotalTrafficSEA</td>\n",
       "      <td>Closed due to accident in #InternationalDistri...</td>\n",
       "      <td>2022-07-15</td>\n",
       "      <td>19:30:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TotalTrafficSEA</td>\n",
       "      <td>Closed due to accident in #InternationalDistri...</td>\n",
       "      <td>2022-07-15</td>\n",
       "      <td>19:30:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>TotalTrafficSEA</td>\n",
       "      <td>Accident.  Four lanes blocked. in #FederalWay ...</td>\n",
       "      <td>2022-07-07</td>\n",
       "      <td>00:30:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>TotalTrafficSEA</td>\n",
       "      <td>Accident. Two right lanes blocked. in #Federal...</td>\n",
       "      <td>2022-07-07</td>\n",
       "      <td>00:15:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>TotalTrafficSEA</td>\n",
       "      <td>Accident. Right lane blocked in #Pacific on SR...</td>\n",
       "      <td>2022-07-06</td>\n",
       "      <td>21:35:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>seattletimes</td>\n",
       "      <td>UPDATE: At 7:13 a.m., four vehicles got into a...</td>\n",
       "      <td>2022-07-08</td>\n",
       "      <td>16:45:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Ablonde20211</td>\n",
       "      <td>Goddammit, West Seattle drivers!! It’s 10PM &amp;a...</td>\n",
       "      <td>2022-07-07</td>\n",
       "      <td>04:55:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            username                                              tweet  \\\n",
       "0    TotalTrafficSEA  Delays up to two hours in #Edmonds/Kingston on...   \n",
       "1    TotalTrafficSEA  Blocked due to accident in #HbrIsland/WestSeat...   \n",
       "2    TotalTrafficSEA  Blocked due to accident in #HbrIsland/WestSeat...   \n",
       "3    TotalTrafficSEA  Closed due to accident in #InternationalDistri...   \n",
       "4    TotalTrafficSEA  Closed due to accident in #InternationalDistri...   \n",
       "..               ...                                                ...   \n",
       "215  TotalTrafficSEA  Accident.  Four lanes blocked. in #FederalWay ...   \n",
       "216  TotalTrafficSEA  Accident. Two right lanes blocked. in #Federal...   \n",
       "217  TotalTrafficSEA  Accident. Right lane blocked in #Pacific on SR...   \n",
       "218     seattletimes  UPDATE: At 7:13 a.m., four vehicles got into a...   \n",
       "219     Ablonde20211  Goddammit, West Seattle drivers!! It’s 10PM &a...   \n",
       "\n",
       "           date      time  \n",
       "0    2022-07-16  16:30:43  \n",
       "1    2022-07-16  02:15:44  \n",
       "2    2022-07-16  02:15:43  \n",
       "3    2022-07-15  19:30:43  \n",
       "4    2022-07-15  19:30:43  \n",
       "..          ...       ...  \n",
       "215  2022-07-07  00:30:43  \n",
       "216  2022-07-07  00:15:43  \n",
       "217  2022-07-06  21:35:43  \n",
       "218  2022-07-08  16:45:36  \n",
       "219  2022-07-07  04:55:27  \n",
       "\n",
       "[220 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9aeab6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d2c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
